{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erencan/anaconda3/envs/gvp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "# model_name = \"prot_bert\"\n",
    "model_name = \"prot_t5_xl_half_uniref50-enc\"\n",
    "\n",
    "if model_name == \"prot_bert\":\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"Rostlab/{model_name}\", do_lower_case=False )\n",
    "    model = BertModel.from_pretrained(f\"Rostlab/{model_name}\")\n",
    "if model_name == \"prot_t5_xl_half_uniref50-enc\":\n",
    "    from transformers import T5EncoderModel, T5Tokenizer\n",
    "    # tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False)\n",
    "    # model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\", do_lower_case=False)\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ATOM_TYPES = 9\n",
    "_SEQ_EMBED_SIZE = 1024\n",
    "_element_mapping = lambda x: {\n",
    "    'H' : 0,\n",
    "    'C' : 1,\n",
    "    'N' : 2,\n",
    "    'O' : 3,\n",
    "    'F' : 4,\n",
    "    'S' : 5,\n",
    "    'Cl': 6, 'CL': 6,\n",
    "    'P' : 7\n",
    "}.get(x, 8)\n",
    "\n",
    "_amino_acids = lambda x: {\n",
    "    'ALA': 0,\n",
    "    'ARG': 1,\n",
    "    'ASN': 2,\n",
    "    'ASP': 3,\n",
    "    'CYS': 4,\n",
    "    'GLU': 5,\n",
    "    'GLN': 6,\n",
    "    'GLY': 7,\n",
    "    'HIS': 8,\n",
    "    'ILE': 9,\n",
    "    'LEU': 10,\n",
    "    'LYS': 11,\n",
    "    'MET': 12,\n",
    "    'PHE': 13,\n",
    "    'PRO': 14,\n",
    "    'SER': 15,\n",
    "    'THR': 16,\n",
    "    'TRP': 17,\n",
    "    'TYR': 18,\n",
    "    'VAL': 19\n",
    "}.get(x, 20)\n",
    "\n",
    "map_amino_3to1 = lambda x: {\n",
    "    'ALA': 'A',\n",
    "    'ARG': 'R',\n",
    "    'ASN': 'N',\n",
    "    'ASP': 'D',\n",
    "    'CYS': 'C',\n",
    "    'GLN': 'Q',\n",
    "    'GLU': 'E',\n",
    "    'GLY': 'G',\n",
    "    'HIS': 'H',\n",
    "    'ILE': 'I',\n",
    "    'LEU': 'L',\n",
    "    'LYS': 'K',\n",
    "    'MET': 'M',\n",
    "    'PHE': 'F',\n",
    "    'PRO': 'P',\n",
    "    'SER': 'S',\n",
    "    'THR': 'T',\n",
    "    'TRP': 'W',\n",
    "    'TYR': 'Y',\n",
    "    'VAL': 'V',\n",
    "}.get(x, '')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "torch.max_split_size_mb = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A R N D C Q E G H I L K M F P S T W Y V [MASK]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 1024)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.max_split_size_mb = 256\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "\n",
    "amino_acids_1_letter = [\n",
    "    'A',  # Alanine\n",
    "    'R',  # Arginine\n",
    "    'N',  # Asparagine\n",
    "    'D',  # Aspartic Acid\n",
    "    'C',  # Cysteine\n",
    "    'Q',  # Glutamine\n",
    "    'E',  # Glutamic Acid\n",
    "    'G',  # Glycine\n",
    "    'H',  # Histidine\n",
    "    'I',  # Isoleucine\n",
    "    'L',  # Leucine\n",
    "    'K',  # Lysine\n",
    "    'M',  # Methionine\n",
    "    'F',  # Phenylalanine\n",
    "    'P',  # Proline\n",
    "    'S',  # Serine\n",
    "    'T',  # Threonine\n",
    "    'W',  # Tryptophan\n",
    "    'Y',  # Tyrosine\n",
    "    'V',  # Valine\n",
    "]\n",
    "\n",
    "amino_acids_1_letter = [\"A R N D C Q E G H I L K M F P S T W Y V [MASK]\"]\n",
    "\n",
    "print(amino_acids_1_letter)\n",
    "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in amino_acids_1_letter]\n",
    "\n",
    "ids = tokenizer.batch_encode_plus(sequences_Example, add_special_tokens=True, padding=True)\n",
    "\n",
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "\n",
    "embedding = embedding.last_hidden_state.cpu().numpy()\n",
    "\n",
    "features = [] \n",
    "for seq_num in range(len(embedding)):\n",
    "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "    seq_emd = embedding[seq_num][:seq_len-1]\n",
    "    features.append(seq_emd)\n",
    "\n",
    "ATOM_TYPES_EMB = features[0]\n",
    "ATOM_TYPES_EMB.shape\n",
    "\n",
    "# torch.save(ATOM_TYPES_EMB, f'data/AMINO_TYPES_andMask_EMB_{model_name}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sequence, length, model, tokenizer, device):\n",
    "    ids = tokenizer.batch_encode_plus(sequence, add_special_tokens=True, padding=\"longest\")\n",
    "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding_rpr = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "    emb = embedding_rpr.last_hidden_state[0,:length] # shape (length x 1024)\n",
    "    print(emb.shape)\n",
    "    emb = emb.mean(dim=0).unsqueeze(0) # shape (1 x 1024)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([1, 1024])\n",
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "# sequence = amino_acids_1_letter\n",
    "# length = len(amino_acids_1_letter)\n",
    "# print(length)\n",
    "\n",
    "# embedding = get_embedding(sequence, length, model, tokenizer, device).detach().cpu()\n",
    "# print(embedding.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
